{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing\n",
    "\n",
    "```\n",
    "Data is loaded, then split into training & testing sets.\n",
    "Standard scaling is also applied to images.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data & Load as numPy Arrays\n",
    "\n",
    "To avoid downloading data set to disk use **sklearn.datasets.fetch_lfw_people**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset Size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "\n",
    "people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# Introspect the image arrays\n",
    "n_samples, h, w = people.images.shape\n",
    "\n",
    "X = people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "y = people.target\n",
    "target_names = people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total Dataset Size:\")\n",
    "print(f\"n_samples: {n_samples}\")\n",
    "print(f\"n_features: {n_features}\")\n",
    "print(f\"n_classes: {n_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training & Test Sets\n",
    "\n",
    "Apply standardised scaling\n",
    "75% Training | 25% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Prior to split, 'random_state' controls the amount of data mixing\n",
    "    # No specific reason as to 42, just allows same result to be produced across a different run\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Remove mean & scale to unit variance to standardise features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction w/ Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 from 966 faces...\n",
      "done in 1.545753002166748s\n",
      "Projecting input data on the eigenfaces orthonormal basis\n",
      "done in 0.06431031227111816s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Compute PCA\n",
    "n_components = 150\n",
    "t0 = time()\n",
    "\n",
    "pca = PCA(n_components = n_components,\n",
    "          svd_solver= \"randomized\",\n",
    "          whiten = True\n",
    "          ).fit(X_train)\n",
    "\n",
    "print(f\"Extracting the top {n_components} from {X_train.shape[0]} faces...\")\n",
    "print(f\"done in {time() - t0}s\")\n",
    "\n",
    "\n",
    "# Data Transformation\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting input data on the eigenfaces orthonormal basis\")\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"done in {time() - t0}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial_verification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
